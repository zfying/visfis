{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3e0e46-c38c-4c0a-90c4-9d760cf313e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import random \n",
    "import nltk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a8dd5f-2eaf-4190-a078-de0749ec1456",
   "metadata": {},
   "source": [
    "# dist shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b153ba3-6050-4d3e-a98b-e7be2f8625c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## read original questions - XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0049b9e-ff68-4f81-813f-7970660c08d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEVR-XAI\n",
    "question_dir = '../data/CLEVR-XAI_v1.0/'\n",
    "\n",
    "_path = os.path.join(question_dir, 'CLEVR-XAI_simple_questions.json')\n",
    "all_simple_qs = json.load(open(_path))['questions']\n",
    "_path = os.path.join(question_dir, 'CLEVR-XAI_complex_questions.json')\n",
    "all_complex_qs = json.load(open(_path))['questions']\n",
    "\n",
    "# both simple/complex qid starts with 0; add complex qid by 100,000\n",
    "for q in all_complex_qs: \n",
    "    q['question_index'] += 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd663d27-b431-41a6-a08d-4ab53a972127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change ans details for CLEVR-XAI\n",
    "def convert_xai_ans_details(qs):\n",
    "    for q in qs:\n",
    "        ans_type = type(q[\"answer\"])\n",
    "        if ans_type != str:\n",
    "            if ans_type == int:\n",
    "                q[\"answer\"] = str(q[\"answer\"])\n",
    "            elif ans_type == bool:\n",
    "                if q[\"answer\"] == False:\n",
    "                    q[\"answer\"] = \"no\"\n",
    "                elif q[\"answer\"] == True:\n",
    "                    q[\"answer\"] = \"yes\"\n",
    "                else:\n",
    "                    raise ValueError(\"unknown bool\")\n",
    "            else: \n",
    "                raise ValueError(\"unknown ans type\")\n",
    "    return qs\n",
    "\n",
    "all_simple_qs = convert_xai_ans_details(all_simple_qs)\n",
    "all_complex_qs = convert_xai_ans_details(all_complex_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34758af-3a58-4570-83f6-f858c55474a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qns = all_simple_qs+all_complex_qs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a66309d-85ce-4e1c-9e42-8bed5b490166",
   "metadata": {
    "tags": []
   },
   "source": [
    "## read original questions - GQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4345fb49-ded3-440b-bb82-3d50cf99f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gqa_data_root = '../data/neg_gqa/GQA/questions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93fead-abee-4a80-a368-3c265fe9d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change qns to list\n",
    "all_qns = []\n",
    "\n",
    "train_qns = json.load(open(os.path.join(gqa_data_root, \"train_balanced_questions.json\")))\n",
    "for qid, value in tqdm(train_qns.items()):\n",
    "    value['question_id'] = qid\n",
    "    all_qns.append(value)\n",
    "del train_qns\n",
    "\n",
    "val_qns = json.load(open(os.path.join(gqa_data_root, \"val_balanced_questions.json\")))\n",
    "for qid, value in tqdm(val_qns.items()):\n",
    "    value['question_id'] = qid\n",
    "    all_qns.append(value)\n",
    "del val_qns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ba097-83d6-43d3-a4f6-6418a3726312",
   "metadata": {
    "tags": []
   },
   "source": [
    "## read original questions - VQA-HAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e9ecec-b386-4d8c-b229-4fb01a8c63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_data_root = '../data/neg_data_vqa/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a00b4e8-fc1f-40f1-bf8b-01d2ee321258",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_train = json.load(open(os.path.join(vqa_data_root, \"v2_mscoco_train2014_annotations.json\"), 'r'))\n",
    "ann_val = json.load(open(os.path.join(vqa_data_root, \"v2_mscoco_val2014_annotations.json\"), 'r'))\n",
    "qns_train = json.load(open(os.path.join(vqa_data_root, \n",
    "                                        \"v2_OpenEnded_mscoco_train2014_questions.json\"), 'r'))\n",
    "qns_val = json.load(open(os.path.join(vqa_data_root, \n",
    "                                      \"v2_OpenEnded_mscoco_val2014_questions.json\"), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d70a918-d86e-44f5-a3af-1671ab474bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_path = os.path.join(vqa_data_root, \"hints/train_hat.pkl\")\n",
    "with open (_path, 'rb') as f:\n",
    "    hints_train = pickle.load(f)\n",
    "    \n",
    "_path = os.path.join(vqa_data_root, \"hints/val_hat.pkl\")\n",
    "with open (_path, 'rb') as f:\n",
    "    hints_val = pickle.load(f)\n",
    "\n",
    "hints_train.update(hints_val)\n",
    "hints = hints_train\n",
    "del hints_train, hints_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ff27e5-c16a-4782-8ac7-2d8b3e0e6dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6af30-b19e-4816-9b1a-44c81c9011ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ann_train['annotations']), len(ann_val['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fa2555-e648-42ad-a5e9-89d22ab19e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ann_train['annotations'])):\n",
    "    assert ann_train['annotations'][i]['question_id'] == qns_train['questions'][i]['question_id']\n",
    "    qns_train['questions'][i].update(ann_train['annotations'][i])\n",
    "del ann_train\n",
    "\n",
    "for i in range(len(ann_val['annotations'])):\n",
    "    assert ann_val['annotations'][i]['question_id'] == qns_val['questions'][i]['question_id']\n",
    "    qns_val['questions'][i].update(ann_val['annotations'][i])\n",
    "del ann_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dccc28-0ea8-4fb6-8514-57b3d6258ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qns = []\n",
    "for qn in tqdm(qns_train['questions']):\n",
    "    if qn['question_id'] in hints:\n",
    "        all_qns.append(qn)\n",
    "del qns_train\n",
    "\n",
    "for qn in tqdm(qns_val['questions']):\n",
    "    if qn['question_id'] in hints:\n",
    "        all_qns.append(qn)\n",
    "del qns_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11eee25-fd44-49d6-b340-534c5b837bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_qns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fdca19-b002-4238-a19f-992bb5254d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'vqa-hat'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c35a4-6d6d-42bd-8c5f-0a45eb65bd22",
   "metadata": {},
   "source": [
    "## grouping QAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d83599-b07c-44be-bdde-26ac9c5096f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups: (q_type, ans) -> group\n",
    "# group: questions (list), concepts (list)\n",
    "groups = {}\n",
    "prefix_length = 3\n",
    "# group simple questions\n",
    "for q in tqdm(all_qns):\n",
    "    \n",
    "    q_type = ' '.join(q['question'].split()[:prefix_length])\n",
    "    \n",
    "    if dataset=='vqa-hat':\n",
    "        ans = q['multiple_choice_answer']\n",
    "    else:\n",
    "        ans = q['answer']\n",
    "    if (q_type, ans) not in groups:\n",
    "        groups[(q_type, ans)] = {'questions': [], 'concepts': []}\n",
    "    \n",
    "    # add question\n",
    "    groups[(q_type, ans)]['questions'].append(q)\n",
    "    # add concepts\n",
    "    set_question = re.split(\"[\\W]+\", q['question'].lower())\n",
    "    set_ans = re.split(\"[\\W]+\", ans.lower())\n",
    "    groups[(q_type, ans)]['concepts'] += set_question + set_ans\n",
    "    groups[(q_type, ans)]['concepts'] = list(set(groups[(q_type, ans)]['concepts']))\n",
    "print(f\"Grouped questions into {len(groups)} groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d028ca-ec9b-415d-84b4-70f162225830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all stop words from concepts\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "for key in tqdm(groups):    \n",
    "    new_concepts = []\n",
    "    for w in groups[key]['concepts']:\n",
    "        if w.lower() not in stop_words and w !='':\n",
    "            new_concepts.append(w)\n",
    "    groups[key]['concepts'] = set(new_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57fc860-7cdf-46df-82aa-1e51f5d48d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize groups\n",
    "all_length = []\n",
    "for key, group in groups.items():\n",
    "    all_length.append(len(group['questions']))\n",
    "all_length = np.array(all_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b612d-7733-4076-87fd-b952bbfcfd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 10\n",
    "np.sum(all_length>=cutoff), np.sum(all_length<cutoff), np.sum(all_length==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41fb64-9ed8-42a4-a024-149eac56a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_length)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8f640-becf-4cc6-8466-f485f19fc8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups[('There is a', 'cylinder')]['questions'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdbfdae-e8cb-43b5-9bfb-266c007e5414",
   "metadata": {},
   "source": [
    "## re-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e678571-df9a-4342-b617-8e57d2d45397",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(all_qns)\n",
    "total_size, len(groups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02d77e-10a0-4873-aa08-454a13a5d788",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = 0\n",
    "for key, value in groups.items():\n",
    "    total_size += len(value['questions'])\n",
    "total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59017c6c-4a4f-4825-b723-e7f29e6f3ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ff7c7-d0c7-4612-844b-d531ac86a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concepts_from_question_list(qs):\n",
    "    \n",
    "    concepts = set()\n",
    "    for q in qs:\n",
    "        if dataset=='vqa-hat':\n",
    "            ans = q['multiple_choice_answer']\n",
    "        else:\n",
    "            ans = q['answer']\n",
    "        \n",
    "        set_question = re.split(\"[\\W]+\", q['question'].lower()) # concepts in question\n",
    "        set_ans = re.split(\"[\\W]+\", ans.lower()) # concepts in answer\n",
    "        concepts = concepts.union(set(set_question + set_ans))\n",
    "    # print(f\"num of concepts: {len(concepts)}\")\n",
    "    # remove stopwords\n",
    "    new_concepts = set()\n",
    "    for w in concepts:\n",
    "        if w.lower() not in stop_words and w !='':\n",
    "            new_concepts = new_concepts.union({w})\n",
    "    # print(f\"after removing stop words: {len(new_concepts)}\")\n",
    "    return new_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd61cd77-fe03-42e3-b698-bbb0379cc30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657387d4-1aa3-4cfe-b283-13bae317b6b2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_GREEDY = True\n",
    "# reduce_simple_ood = False\n",
    "USE_SOFT_SHIFT = False\n",
    "soft_shift_ratio = 0.2\n",
    "ood_ratio = 0.15\n",
    "progress_list = []\n",
    "speed_up_val_concepts_size = 20\n",
    "\n",
    "# questions\n",
    "all_val_questions = []\n",
    "all_train_questions = []\n",
    "# concepts\n",
    "cur_train_concepts = set()\n",
    "cur_val_concepts = set()\n",
    "remaining_val_concepts = set()\n",
    "# key\n",
    "visited_keys = []\n",
    "\n",
    "# shuffle\n",
    "items = list(groups.items())\n",
    "random.shuffle(items)\n",
    "for index,(key, value) in enumerate(items):\n",
    "    # randomly select one group\n",
    "    if key in visited_keys:\n",
    "        continue\n",
    "    qs = value['questions']\n",
    "    concepts = value['concepts']\n",
    "    \n",
    "    if USE_SOFT_SHIFT:\n",
    "        # split qs 8:2\n",
    "        random.shuffle(qs)\n",
    "        cutoff = int(len(qs)*soft_shift_ratio)\n",
    "        qs_20 = qs[:cutoff]\n",
    "        qs_80 = qs[cutoff:]\n",
    "        concepts_20 = get_concepts_from_question_list(qs_20)\n",
    "        concepts_80 = get_concepts_from_question_list(qs_80)\n",
    "        # randomly assign to train/val\n",
    "        if np.random.rand()>0.5:\n",
    "            # val\n",
    "            all_val_questions += qs_20\n",
    "            cur_val_concepts = cur_val_concepts.union(concepts_20)\n",
    "            # train\n",
    "            all_train_questions += qs_80\n",
    "            cur_train_concepts = cur_train_concepts.union(concepts_80)\n",
    "            # remaining val\n",
    "            remaining_val_concepts = remaining_val_concepts.union(concepts_20)\n",
    "            remaining_val_concepts = remaining_val_concepts - concepts_80\n",
    "        else:\n",
    "            # val\n",
    "            all_val_questions += qs_80\n",
    "            cur_val_concepts = cur_val_concepts.union(concepts_80)\n",
    "            # train\n",
    "            all_train_questions += qs_20\n",
    "            cur_train_concepts = cur_train_concepts.union(concepts_20)\n",
    "            # remaining val\n",
    "            remaining_val_concepts = remaining_val_concepts.union(concepts_80)\n",
    "            remaining_val_concepts = remaining_val_concepts - concepts_20\n",
    "    else: # hard shift\n",
    "        all_val_questions += qs\n",
    "        cur_val_concepts = cur_val_concepts.union(concepts)\n",
    "        # remaining \n",
    "        l = len(remaining_val_concepts)\n",
    "        remaining_val_concepts = remaining_val_concepts.union(concepts)\n",
    "        print(f\"increase concepts by {len(remaining_val_concepts) - l}\")\n",
    "    \n",
    "    # update\n",
    "    visited_keys.append(key)\n",
    "    progress_list.append(len(all_val_questions) / (total_size*ood_ratio))\n",
    "    # print(f\"visited key: f{key}\")\n",
    "    \n",
    "    # end when reaching desired ood size\n",
    "    if len(all_val_questions) > total_size*ood_ratio:\n",
    "        break\n",
    "    \n",
    "    if USE_GREEDY: # find group with max coverage\n",
    "        # get uncovered val concepts\n",
    "        if len(remaining_val_concepts) <= speed_up_val_concepts_size: # if train concepts cover all val concepts\n",
    "            # print(index, len(all_val_questions) / total_size*ood_ratio)\n",
    "            continue\n",
    "        print(f\"start greedy search with {len(remaining_val_concepts)} remaining concepts...\")\n",
    "        max_intersect = -1\n",
    "        max_key = None\n",
    "\n",
    "        next_items = list(groups.items())\n",
    "        random.shuffle(next_items)\n",
    "        for next_key, next_value in next_items:\n",
    "            if next_key == key: # ignore current\n",
    "                continue\n",
    "            elif next_key in visited_keys: # ignore visied keys\n",
    "                continue \n",
    "            else: \n",
    "                if USE_SOFT_SHIFT:\n",
    "                    # split qs 8:2\n",
    "                    qs = next_value['questions']\n",
    "                    random.shuffle(qs)\n",
    "                    cutoff = int(len(qs)*soft_shift_ratio)\n",
    "                    qs_20 = qs[:cutoff]\n",
    "                    qs_80 = qs[cutoff:]\n",
    "                    concepts_20 = get_concepts_from_question_list(qs_20)\n",
    "                    concepts_80 = get_concepts_from_question_list(qs_80)\n",
    "                    # random assign\n",
    "                    if np.random.rand()>0.5:\n",
    "                        train_qs = qs_20\n",
    "                        train_concepts = concepts_20\n",
    "                        val_qs = qs_80\n",
    "                        val_concepts = concepts_80\n",
    "                    else:\n",
    "                        train_qs = qs_80\n",
    "                        train_concepts = concepts_80\n",
    "                        val_qs = qs_20\n",
    "                        val_concepts = concepts_20\n",
    "                else:\n",
    "                    train_qs = next_value['questions']\n",
    "                    train_concepts = next_value['concepts']\n",
    "\n",
    "                len_intersect = len(remaining_val_concepts.intersection(train_concepts))\n",
    "                # update max\n",
    "                if len_intersect > max_intersect:\n",
    "                    max_intersect = len_intersect\n",
    "                    max_key = next_key\n",
    "                    max_train_qs = train_qs\n",
    "                    max_train_concepts = train_concepts\n",
    "                    if USE_SOFT_SHIFT:\n",
    "                        max_val_qs = val_qs\n",
    "                        max_val_concepts = val_concepts\n",
    "\n",
    "        if max_key == None: # no group left\n",
    "            break\n",
    "        # add to train/val\n",
    "        assert(max_key not in visited_keys)\n",
    "        if USE_SOFT_SHIFT:\n",
    "            # add val\n",
    "            all_val_questions += max_val_qs\n",
    "            cur_val_concepts = cur_val_concepts.union(max_val_concepts)\n",
    "            # remaining\n",
    "            remaining_val_concepts = remaining_val_concepts.union(max_val_concepts)\n",
    "        # add train\n",
    "        all_train_questions += max_train_qs\n",
    "        cur_train_concepts = cur_train_concepts.union(max_train_concepts)\n",
    "        # remaining\n",
    "        remaining_val_concepts = remaining_val_concepts - max_train_concepts\n",
    "        # update\n",
    "        visited_keys.append(max_key)\n",
    "        progress_list.append(len(all_val_questions) / (total_size*ood_ratio))\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(index, len(all_val_questions) / (total_size*ood_ratio))\n",
    "    if USE_GREEDY:\n",
    "        print(f\"max intersection {max_intersect}\")\n",
    "    \n",
    "\n",
    "print(\"finished assigning val set\", len(all_train_questions), len(all_val_questions))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca28fe4-d25a-4a92-819c-af3acbce98f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_train_questions), len(all_val_questions), len(visited_keys), len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03da8be6-399a-4e67-ac3a-6244833532ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(progress_list)), progress_list)\n",
    "print(len(progress_list))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b58b5c-24a0-4951-b8fe-44bccad50668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign all rest groups to train\n",
    "for key,value in groups.items():\n",
    "    if key in visited_keys:\n",
    "        continue\n",
    "    else:\n",
    "        # assign to train\n",
    "        visited_keys.append(key)\n",
    "        all_train_questions += value['questions']\n",
    "print(\"finished assigning train set\", len(all_train_questions), len(all_val_questions))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7590127b-b130-4715-a8fb-c2a183d5c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_train_questions) + len(all_val_questions), total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986242cf-5642-4cb1-97b7-77372f23aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train into train/dev/test-id -> 6:1:1.5\n",
    "random.shuffle(all_train_questions)\n",
    "unit_length = int(len(all_train_questions) / 8.5)\n",
    "real_train_questions = all_train_questions[:unit_length*6]\n",
    "dev_questions = all_train_questions[unit_length*6 : unit_length*7]\n",
    "test_id_questions = all_train_questions[unit_length*7 :]\n",
    "len(real_train_questions), len(dev_questions), len(test_id_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf3560-437e-406c-855d-2bdbd2d0c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train_concepts = get_concepts_from_question_list(real_train_questions)\n",
    "'train concept size', len(real_train_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f91efaa-d67b-4638-a44b-efa77adf3887",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_concepts = get_concepts_from_question_list(dev_questions)\n",
    "'dev concept size', len(dev_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ddcde6-6797-4d20-8d9f-e196947e3274",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id_concepts = get_concepts_from_question_list(test_id_questions)\n",
    "print(f'test-id concept size: {len(test_id_concepts)}')\n",
    "print(f'covered concept size id: {len(real_train_concepts.intersection(test_id_concepts))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bdeb8d-ae1d-4bd0-85e5-29133db450ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_val_concepts = get_concepts_from_question_list(all_val_questions)\n",
    "print(f'test-ood concept size: {len(all_val_concepts)}')\n",
    "print(f'covered concept size ood: {len(real_train_concepts.intersection(all_val_concepts))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc1c39-8517-4c46-acc3-e2293d5addef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'covered concept size', len(real_train_concepts.intersection(all_val_concepts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0154973-362b-4fd6-bb0e-6eea0b5c4770",
   "metadata": {
    "tags": []
   },
   "source": [
    "# save - XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e5c4c-2e0a-4c5a-b56e-24066e8e5dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "_path = os.path.join(question_dir, 'CLEVR-XAI_simple_questions.json')\n",
    "simple_qs = json.load(open(_path))\n",
    "_path = os.path.join(question_dir, 'CLEVR-XAI_complex_questions.json')\n",
    "complex_qs = json.load(open(_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707bf80a-0879-4497-b32e-56146b7920c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_qs['info'] == simple_qs['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237dfd65-fb71-41a7-bff5-b73143259528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "new_train_qs = {}\n",
    "new_train_qs['info'] = simple_qs['info']\n",
    "new_train_qs['questions'] = real_train_questions\n",
    "\n",
    "new_dev_qs = {}\n",
    "new_dev_qs['info'] = simple_qs['info']\n",
    "new_dev_qs['questions'] = dev_questions\n",
    "\n",
    "new_test_id_qs = {}\n",
    "new_test_id_qs['info'] = simple_qs['info']\n",
    "new_test_id_qs['questions'] = test_id_questions\n",
    "\n",
    "new_test_ood_qs = {}\n",
    "new_test_ood_qs['info'] = simple_qs['info']\n",
    "new_test_ood_qs['questions'] = all_val_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c7635e-ca8f-4846-8ec1-7c611d0dd099",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_train_qs['questions']), len(new_test_ood_qs['questions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38bec93-aea8-437c-91a6-c6f333767fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../data/neg_data_xaicp/questions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b58d4-0597-4899-8cd7-96191d6df117",
   "metadata": {},
   "outputs": [],
   "source": [
    "_path = os.path.join(save_dir, 'CLEVRXAICP_train_questions.json')\n",
    "with open(_path, 'w') as f:\n",
    "    json.dump(new_train_qs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228daa59-f413-4592-83e7-dc74de2c28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_path = os.path.join(save_dir, 'CLEVRXAICP_dev_questions.json')\n",
    "with open(_path, 'w') as f:\n",
    "    json.dump(new_dev_qs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9bf8c5-fea1-4064-b700-fdfc79a29fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_path = os.path.join(save_dir, 'CLEVRXAICP_test-id_questions.json')\n",
    "with open(_path, 'w') as f:\n",
    "    json.dump(new_test_id_qs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f47d9b3-0076-4ede-899d-acdea2cb8d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "_path = os.path.join(save_dir, 'CLEVRXAICP_test-ood_questions.json')\n",
    "with open(_path, 'w') as f:\n",
    "    json.dump(new_test_ood_qs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05c0d69-c051-49e7-8fd8-6079db93989a",
   "metadata": {},
   "source": [
    "# save - hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72122b10-6aa9-4238-af63-82ad4090b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "_path = os.path.join(vqa_data_root, 'v2_OpenEnded_mscoco_train2014_questions.json')\n",
    "qns_train = json.load(open(_path))\n",
    "_path = os.path.join(vqa_data_root, 'v2_OpenEnded_mscoco_val2014_questions.json')\n",
    "qns_val = json.load(open(_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e23465-f5a7-4260-81a3-a8052ea07e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into questions and annotations\n",
    "_path = os.path.join(vqa_data_root, 'v2_mscoco_train2014_annotations.json')\n",
    "ann_train = json.load(open(_path))\n",
    "_path = os.path.join(vqa_data_root, 'v2_mscoco_val2014_annotations.json')\n",
    "ann_val = json.load(open(_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ca358-05de-4a38-a647-3c0ec02c01cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_ann_qns(full_qns):\n",
    "    anns_only = []\n",
    "    qns_only = []\n",
    "    for full_qn in full_qns:\n",
    "        ann = {}\n",
    "        qn = {}\n",
    "        # update qn\n",
    "        qn['image_id'] = full_qn['image_id']\n",
    "        qn['question'] = full_qn['question']\n",
    "        qn['question_id'] = full_qn['question_id']\n",
    "        # update ann\n",
    "        ann['question_type'] = full_qn['question_type']\n",
    "        ann['multiple_choice_answer'] = full_qn['multiple_choice_answer']\n",
    "        ann['answers'] = full_qn['answers']\n",
    "        ann['image_id'] = full_qn['image_id']\n",
    "        ann['answer_type'] = full_qn['answer_type']\n",
    "        ann['question_id'] = full_qn['question_id']\n",
    "        # append\n",
    "        anns_only.append(ann)\n",
    "        qns_only.append(qn)\n",
    "    return qns_only, anns_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d970d4-493b-4e76-8b62-274371a6dfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qns_only, train_anns_only = split_into_ann_qns(real_train_questions)\n",
    "dev_qns_only, dev_anns_only = split_into_ann_qns(dev_questions)\n",
    "test_id_qns_only, test_id_anns_only = split_into_ann_qns(test_id_questions)\n",
    "test_ood_qns_only, test_ood_anns_only = split_into_ann_qns(all_val_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b07605a-01cb-4f52-b09b-b03be2f9b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create qns\n",
    "qns_train['questions'] = train_qns_only\n",
    "\n",
    "qns_val['questions'] = None\n",
    "qns_dev = qns_val.copy()\n",
    "qns_test_id = qns_val.copy()\n",
    "qns_test_ood = qns_val.copy()\n",
    "\n",
    "qns_dev['questions'] = dev_qns_only\n",
    "qns_test_id['questions'] = test_id_qns_only\n",
    "qns_test_ood['questions'] = test_ood_qns_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc9dc0-12cb-4d38-becb-5dab6f3395e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_path = os.path.join(vqa_data_root, 'hatcp_train_questions.json')\n",
    "with open(_path, 'w') as outfile:\n",
    "    json.dump(qns_train, outfile)\n",
    "    \n",
    "_path = os.path.join(vqa_data_root, 'hatcp_dev_questions.json')\n",
    "with open(_path, 'w') as outfile:\n",
    "    json.dump(qns_dev, outfile)\n",
    "\n",
    "_path = os.path.join(vqa_data_root, 'hatcp_test-id_questions.json')\n",
    "with open(_path, 'w') as outfile:\n",
    "    json.dump(qns_test_id, outfile)\n",
    "    \n",
    "_path = os.path.join(vqa_data_root, 'hatcp_test-ood_questions.json')\n",
    "with open(_path, 'w') as outfile:\n",
    "    json.dump(qns_test_ood, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d8ce6-84a5-473f-a432-a528a78dcbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create anns\n",
    "ann_train['annotations'] = train_anns_only\n",
    "\n",
    "ann_val['annotations'] = None\n",
    "ann_dev = qns_val.copy()\n",
    "ann_test_id = qns_val.copy()\n",
    "ann_test_ood = qns_val.copy()\n",
    "\n",
    "ann_dev['annotations'] = dev_anns_only\n",
    "ann_test_id['annotations'] = test_id_anns_only\n",
    "ann_test_ood['annotations'] = test_ood_anns_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba15d7c6-63d6-4f71-af7e-0fb2d807b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_path = os.path.join(vqa_data_root, 'hatcp_train_annotations.json')\n",
    "with open(_path, 'w') as outfile:\n",
    "    json.dump(ann_train, outfile)\n",
    "    \n",
    "_path = os.path.join(vqa_data_root, 'hatcp_dev_annotations.json')\n",
    "with open(_path, 'w') as outfile:\n",
    "    json.dump(ann_dev, outfile)\n",
    "\n",
    "_path = os.path.join(vqa_data_root, 'hatcp_test-id_annotations.json')\n",
    "with open(_path, 'w') as outfile:\n",
    "    json.dump(ann_test_id, outfile)\n",
    "\n",
    "_path = os.path.join(vqa_data_root, 'hatcp_test-ood_annotations.json')\n",
    "with open(_path, 'w') as outfile:\n",
    "    json.dump(ann_test_ood, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
